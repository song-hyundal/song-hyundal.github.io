{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmmv8qDrei/sZio9gbYzHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/song-hyundal/song-hyundal.github.io/blob/master/1%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM7T-XR_NB69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ALhC5Oiw9g",
        "colab_type": "text"
      },
      "source": [
        " # **인공지능의 적용 예시**\n",
        " \n",
        " 1. **언어**\n",
        "\n",
        " 네이버 파파고(NAVER Papago)\n",
        "\n",
        "  ![네이버 파파고](https://papago.naver.com/static/img/papago_og.png)\n",
        "  \n",
        " 누구나 한번쯤은 언어의 장벽에 맞닥뜨린적이 있을 것이다. 그렇다고 일일히 사전을 뒤져가며 번역하거나 번역가에게 일을 맡기기에는 시간이나 비용이 너무 많이 소모된다. 그런 이들을 위해 만들어진 것이 바로 번역기. 하지만 기존 번역기들은 생각보다 오류가 많아 번역할 문장이 많을수록 제대로된 번역문을 얻기란 쉽지가 않다. 만약에 번역기에 인공지능이 붙어 똑똑해진다면 어떻게 될까?\n",
        "\n",
        " 그렇게 만들어진 것이 바로 파파고, 네이버가 자체적으로 개발한 인공신경망 기반의 기계 번역 기술인 NMT(Neural Machine Translation)를 이용한 번역 서비스다. NMT는 기존의 규칙기반 기계번역인 RBMT(Rule Based Machine Translation)이나 통계적 기계번역인 SMT(Statistical Machine Translation)보다 몇 단계 진화한 방식으로 입력된 문장을 쪼개어 번역하는 것이 아니라 문구를 통째로 번역하기 때문에 맥락이 고려된 자연스러운 번역 결과를 얻을 수 있다는 것이 특징이다.\n",
        "\n",
        " 기존의 기계번역인 RBMT는 언어의 구조와 문법을 바탕으로 규칙을 만들어 번역하는 방법이라 문법에 맞지 않는 문장은 제대로 번역되지 않고, SMT는 빈도수를 기반으로 이뤄지기 때문에 인터넷 상에 cat이라는 단어만 많고 kitten이라는 단어가 별로 없다면 kitten이라는 단어를 제대로 번역하지 못한다.\n",
        "\n",
        " 그러나 NMT는 대용량의 학습 데이터와 몇 차원 벡터로 표현할 것인지의 정보, 학습에 필요한 변수 정보만 사람이 지정해주면 기계가 알아서 번역법을 학습한다. 입력 문장이 들어오면, 이 문장을 가상 공간의 하나의 점을 의미하는 벡터(좌표값)와 같은 숫자로 변환하고, 학습 데이터를 통해 배운 가중치를 더해 번역을 수행한다. 벡터에는 단어와 구절, 어순 정보까지 다 들어 있다. 인공신경망 기계번역 방식이 문맥을 그만큼 많이 본다는 뜻이다. 이 때문에 번역도 훨씬 자연스럽다.<sup>[1](#footnote_1)</sup>\n",
        "\n",
        " 현재 파파고는 번역 어플리케이션으로도 제공되고있으며 네이버 클라우드 플랫폼(NAVER CLOUD PLATFORM)을 통해 번역 API 서비스를 제공하고있다.\n",
        "\n",
        " \n",
        " 2. **음성**\n",
        " \n",
        " 프로젝트 유포니아(Project Euphonia)\n",
        "\n",
        " ![구글](https://www.google.co.kr/images/branding/googlelogo/2x/googlelogo_color_160x56dp.png)\n",
        "\n",
        " 발음이 정확하지 못한 구음장애인들은 음성인식 서비스가 아무리 발전해도 그 혜택을 누리기가 어렵다. 그렇기에 구글에서는 ‘프로젝트 유포니아’팀 주도로 뇌졸중·근위축측삭경화증(ALS)·다발성 경화증·외상성 뇌손상·파킨슨병 등의 영향으로 정확한 발음을 내는 데 어려움을 겪는 이들을 위한 음성 인식 서비스 개발을 본격 추진하고 있다.<sup>[2](#footnote_2)</sup>\n",
        "\n",
        " 보통 음성인식이 작동하는 방식은 다음과 같다. 음성표본을 모아 파형 이미지로 변환하여 각 이미지가 무엇을 의미하는지 태그를 붙이고 이렇게 만들어진 표본 수백만 개를 사용해 딥러닝 모델이 입력된 소리를 해당하는 단어로 출력하도록 훈련한다. 그런 다음 알고리즘이 문법과 구문론 같은 규칙을 사용하여 문장의 각 단어를 예측한다. 문제는 구음장애인의 발음이 음성표본과 큰 차이를 보이기 때문에 제대로 음성인식을 못 한다는 것이다.\n",
        "\n",
        " 그래서 구글은 보스턴의 비영리 생명 공학 연구 기관인 ALS TDI(ALS Therapy Development Institute)와 협력하여 ALS 환자의 음성표본을 수집하여 구글의 표준 음성 인식 알고리즘을 훈련시키고있다. 프로젝트 유포니아 관계자는 이를 통해서 구음장애인들도 충분히 음성인식 서비스를 누릴 수 있게 하는 것이 첫 번째 목표이며, 나아가 구음장애인들의 목소리를 재구성해 뚜렷한 발음을 출력할 수 있게 하는 것이 두 번째 목표라고 언급했다.\n",
        " \n",
        " 하단 이미지를 클릭하면 약 40분 길이의 관련영상을 유튜브에서 시청할 수 있다.\n",
        " [![Age of A.I.](https://i.ytimg.com/vi/UwsrzCVZAb8/maxresdefault.jpg)](https://www.youtube.com/watch?v=V5aZjsWM2wo)\n",
        "\n",
        " 3. **이미지**\n",
        " \n",
        " 앤트러피(Entrupy)\n",
        "\n",
        " ![앤트러피](https://i2.wp.com/www.entrupy.com/wp-content/uploads/2018/01/Entrupy-Logo.png?fit=500%2C140&ssl=1)\n",
        "\n",
        " 명품가방을 소유하는 것은 많은 사람들에게 기분좋은 일이다. 하지만 만약 큰돈을 들여 구매한 명품가방이 소위 '짝퉁'이라면? 가볍게 웃고넘길만한 일이 아니다. 문제는 최근 위조 기술이 매우 고도화되어 전문가라 해도 육안으로는 진짜 명품인지 짝퉁인지 구분해내기가 쉽지 않다는 것이다. 전문가마저 속을정도로 정교한데 비전문가인 고객이 어떻게 판별을 할 수 있겠는가.\n",
        "\n",
        " 이를 가능하게 해주는 것이 인공지능 스캐너 앤트러피다. 앤트러피는 가방, 신발 등 명품 제품의 표면을 사진으로 찍으면 300만 장의 사진을 학습한 AI가 이미지를 분석하여 진품 여부를 판별해 준다. 이 시스템은 제품을 현미경 사진으로 찍은 다음 사물을 260배 확대하여 육안으로 찾아내기 어려운 비정상적인 패턴, 즉 인장이나 가죽 잔주름 사이의 작은 공백, 페인트칠 등을 보고 진품 여부를 판별한다. 이 시스템의 정확도는 98%이며 일상 중 언제 어디서든 진품 판별이 필요할 때 15초의 시간으로 확인이 가능하다.<sup>[3](#footnote_3)</sup>\n",
        " \n",
        " 4. **자율주행**\n",
        "\n",
        " 퀄컴 스냅드래곤 라이드 플랫폼(Qualcomm Snapdragon Ride Platfrom)\n",
        "\n",
        " ![퀄컴](https://cphoto.asiae.co.kr/listimglink/6/2019121508323245462_1576366352.jpg)\n",
        "\n",
        " 미래에 대한 상상을 바탕으로 만들어진 SF영화를 보다보면 종종 자동차가 운전자 없이 인공지능을 통해 자동으로 주행하는 모습을 볼 수 있다. 영화 속에서 인공지능이 운전하는 자동차는 항상 교통법규를 준수하고 잠깐이라도 시선을 다른 곳에 두는 일도 없으며 베테랑 운전자보다 훨씬 더 안전하고 편안한 주행을 제공한다. 몇년전이었다면 대부분의 사람들이 영화 속이니까 가능한 일이라고 말했을 것이다. 하지만 이 상상을 현실로 끌어올리려는 사람들이 있다.\n",
        "\n",
        " 최근 몇년간 인공지능 분야가 눈부신 발전을 이룩하면서 자율주행 자동차에 대한 연구또한 활발하게 이루어졌다. 자율주행이 이루어지게 하기 위해서 인지∙판단∙제어 등 세 가지 기능이 반드시 필요하다. 인지 기능은 카메라∙레이더∙라이다(LiDAR) 등 차체 내 센서 정보를 처리해 주변 환경 정보를 알아차리는 것, 판단 기능은 인지된 정보를 이용해 향후 벌어질 일을 예측한 후 가장 안전하고 빠른 차량 궤적을 생성하는 것, 제어 기능은 최종적으로 생성된 차량 궤적을 부드럽고 정확하게 따라갈 수 있도록 운전대∙액셀러레이터∙브레이크를 조작하는 것이다. <sup>[4](#footnote_4)</sup>\n",
        "\n",
        " 하지만 이 모두는 사람이 설계한 범위 안에서 작동하기 때문에 설계 시점에서 예상치 못한 상황엔 적절히 대처할 수 없다. 그걸 극복하기 위해 기능적 구분과 설계 없이 운전에 필요한 과정을 통째로 학습하는 딥러닝으로 자율주행 알고리즘을 구성한다면 어떻게 될까?\n",
        "\n",
        " 이렇게 운전과정을 통째로 학습하는 자율주행 방식을 엔드-투-엔드(end-to-end) 자율주행이라고 한다. 엔드투엔드 자율주행 자동차는 운전에 필요한 센서 데이터를 직접 입력 받고 다양한 운행 상황에 대해 학습한 후 스티어링(steering)과 액셀러레이터, 브레이크 값을 직접 출력해낸다. 즉 딥러닝 알고리즘 안에서 인지∙판단∙제어 기능이 처음부터 끝까지 네트워크로 구현되는 것이다.\n",
        " \n",
        " 퀄컴은 이러한 엔드-투-엔드 자율주행을 실현하기 위해 스냅드래곤 라이드 플랫폼을 구축했다. 스냅드래곤 라이드 플랫폼은 하드웨어, 소프트웨어, 오픈 스택, 개발 키트, 그리고 강력한 파트너 생태계를 통합하여, 변화하는 산업과 향상된 안전성, 편의성, 그리고 자율주행 기술에 대한 소비자의 니즈에 맞춰 대응할 수 있는 강력한 플랫폼으로 자리잡을 것이다.\n",
        "\n",
        "\n",
        " <a name=\"footnote_1\">1</a> : [노자운, 2016.11.10, [한국어와 인공지능]⑦ 네이버 김준석 연구원 \"인공신경망 번역 성능 2배 이상..'파파고' 연계 서비스 쏟아진다\", 조선비즈](https://news.v.daum.net/v/20161110112405315)\n",
        "\n",
        " <a name=\"footnote_2\">2</a> : [한광범, 2019.05.09, [구글I/O 2019] 구글 핵심 가치는 접근성…관련 기술 개발 주력, 이데일리](https://www.edaily.co.kr/news/read?newsId=01485846622487280&mediaCodeNo=257)\n",
        "\n",
        " <a name=\"footnote_3\">3</a> : [전승진, 2019.12.09, AI(인공지능) 이미지 인식 기술, AI타임스](http://www.aitimes.com/news/articleView.html?idxno=123173)\n",
        "\n",
        " <a name=\"footnote_4\">4</a> : [조기춘, 2018.04.12, 자율주행 자동차, ‘딥러닝’으로 시동 건다, SAMSUNG Newsroom](https://news.samsung.com/kr/%EC%9E%90%EC%9C%A8%EC%A3%BC%ED%96%89-%EC%9E%90%EB%8F%99%EC%B0%A8-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9C%BC%EB%A1%9C-%EC%8B%9C%EB%8F%99-%EA%B1%B4%EB%8B%A4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ECwh3qWNnQc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}